#!/usr/bin/env python
# coding: utf-8

# In[ ]:


from __future__ import print_function
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import os
from googleapiclient.discovery import build
from httplib2 import Http
from oauth2client import file, client, tools
from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload
import pickle
import os.path
from googleapiclient.discovery import build
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
import  warnings
from    selenium import webdriver
from    selenium.webdriver.support.ui import WebDriverWait
from    selenium.webdriver.support import expected_conditions as EC
from    selenium.webdriver.common.by import By
from    selenium.webdriver.common.keys import Keys 
from    selenium.webdriver.common.action_chains import ActionChains
from    selenium.common.exceptions import NoSuchElementException,StaleElementReferenceException
from    bs4      import BeautifulSoup
import  time
import  pyperclip
import  requests
import  datetime
import  pymssql
import  pandas as pd
from  pandas.core.frame import DataFrame
import  matplotlib.pyplot as plt
import  chromedriver_autoinstaller
import  subprocess
from    selenium import webdriver
from    selenium.webdriver.chrome.options import Options
from    selenium.webdriver.common.alert import Alert
import  chromedriver_autoinstaller
import  subprocess
import  shutil 
import  xlrd
import  openpyxl 
import  pygsheets
import  csv
import  re
import  webbrowser
import  os
import  sys
import  urllib.request
import  json
from    pandas.io.json import json_normalize
import  hashlib
import  hmac
import  base64
import  numpy as np
import  autoit #autoit는 반드시 autoit 프로그램이 깔려있어야됨
import  pyautogui
from PIL import ImageGrab
try:
    from PIL import Image
except ImportError:
    import Image
import pytesseract
import cv2
import numpy as np
import glob
from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
import io

warnings.filterwarnings('ignore')

try:
    shutil.rmtree(r"c:\chrometemp")  #쿠키 / 캐쉬파일 삭제
except FileNotFoundError:
    pass
subprocess.Popen(r'C:\Program Files\Google\Chrome\Application\chrome.exe --remote-debugging-port=9222 --user-data-dir="C:\chrometemp"') # 디버거 크롬 구동
option = Options()
option.add_experimental_option("debuggerAddress", "127.0.0.1:9222")
chrome_ver = chromedriver_autoinstaller.get_chrome_version().split('.')[0]
try:
    driver = webdriver.Chrome(f'./{chrome_ver}/chromedriver.exe', options=option)
except:
    chromedriver_autoinstaller.install(True)
    driver = webdriver.Chrome(f'./{chrome_ver}/chromedriver.exe', options=option)
driver.maximize_window() #최대창
time.sleep(3)    
driver.implicitly_wait(10)

action = ActionChains(driver) #액션지정


#################### 네이버 데이터랩 Top 500 키워드 뽑기 ####################


#기기별 전체:   //*[@id="18_device_0"] 
#성별 전체:   //*[@id="19_gender_0"]
#연령 전체: //*[@id="20_age_0"]
#조회하기 클릭:  //*[@id="content"]/div[2]/div/div[1]/div/a

driver.get(url='https://datalab.naver.com/shoppingInsight/sCategory.naver')
time.sleep(1)

driver.find_element(By.XPATH, '//*[@id="18_device_0"]').click() #기기별 클릭
#time.sleep(0.5)
driver.find_element(By.XPATH, '//*[@id="19_gender_0"]').click() #성별 클릭
#time.sleep(0.5)
driver.find_element(By.XPATH, '//*[@id="20_age_0"]').click() #연령별 클릭
#time.sleep(0.5)


driver.find_element(By.XPATH, '//*[@id="content"]/div[2]/div/div[1]/div/div/div[1]/div/div[1]/span').click() #분야 클릭
#time.sleep(0.5)

driver.find_element(By.XPATH, '//*[@id="content"]/div[2]/div/div[1]/div/div/div[1]/div/div[1]/ul/li[4]/a').click() #디지털/가전 클릭
#time.sleep(0.5)

driver.find_element(By.XPATH, '//*[@id="content"]/div[2]/div/div[1]/div/a').click() #조회하기 클릭
#time.sleep(1)




#상품정보1 : //*[@id="content"]/div[2]/div/div[2]/div[2]/div/div/div[1]/ul/li[1]/a
#상품정보2 : //*[@id="content"]/div[2]/div/div[2]/div[2]/div/div/div[1]/ul/li[2]/a
#상품정보3 : //*[@id="content"]/div[2]/div/div[2]/div[2]/div/div/div[1]/ul/li[3]/a

from openpyxl import Workbook
wb = Workbook()
ws = wb.create_sheet('keyword')
wb.remove_sheet(wb['Sheet'])
ws.append((['No', '인기검색어']))

for i in range(0, 25) :
    for j in range(1, 21) :
        path = f'//*[@id="content"]/div[2]/div/div[2]/div[2]/div/div/div[1]/ul/li[{j}]/a'
        result= driver.find_element(By.XPATH, path).text
        print(result.split('\n'))
        time.sleep(0.1)
        ws.append(result.split('\n'))
    driver.find_element(By.XPATH, '//*[@id="content"]/div[2]/div/div[2]/div[2]/div/div/div[2]/div/a[2]').click()
    time.sleep(0.1)
        
        
wb.save('C:/Users/user/raw/product_kw/naverdatalabtop500.xlsx')
wb.close()

driver.close()
driver.quit()

print("네이버 데이터랩 Top 500 키워드 뽑기 완료")


time.sleep(3)

#################### 네이버 데이터랩 Top 500 키워드 검색량 뽑기 ####################

#import pandas as pd

naver_kws = pd.read_excel('C:/Users/user/raw/product_kw/naverdatalabtop500.xlsx')

f =  open('C:/Users/user/raw/product_kw/naverdatalabtop500_volumes.csv', 'w', encoding='utf-8-sig') #csv파일 데이터 넣을거 생성
f.write("No,Keyword,SVs"+'\n') #컬럼명 입력


for j in range(0, len(naver_kws)) :
    kw = naver_kws.iloc[j]['인기검색어']
    BASE_URL = 'https://api.naver.com'
    API_KEY = ''
    SECRET_KEY = ''
    CUSTOMER_ID = ''
    def generate(timestamp, method, uri, secret_key):
        message = "{}.{}.{}".format(timestamp, method, uri)
        #hash = hmac.new(bytes(secret_key, "utf-8"), bytes(message, "utf-8"), hashlib.sha256)
        hash = hmac.new(secret_key.encode("utf-8"), message.encode("utf-8"), hashlib.sha256)
        hash.hexdigest()
        return base64.b64encode(hash.digest())
    def get_header(method, uri, api_key, secret_key, customer_id):
        timestamp = str(int(time.time() * 1000))
        signature = generate(timestamp, method, uri, SECRET_KEY)
        return {'Content-Type': 'application/json; charset=UTF-8', 'X-Timestamp': timestamp, 'X-API-KEY': API_KEY, 'X-Customer': str(CUSTOMER_ID), 'X-Signature': signature}

    dic_return_kwd = {}
    naver_ad_url = '/keywordstool'
    #_kwds_string = '원피스' #1개일경우
    #_kwds_string = ['나이키', '원피스', '운동화'] #키워드 여러개일경우
    method = 'GET'
    prm = {'hintKeywords' : kw , 'showDetail':1}
    #    ManageCustomerLink Usage Sample
    r = requests.get(BASE_URL + naver_ad_url, params=prm, headers=get_header(method, naver_ad_url, API_KEY, SECRET_KEY, CUSTOMER_ID))

    r_data = r.json()
    #naver_ad_summary = pd.DataFrame(r_data['keywordList'])  
    #keyword_sv_results = naver_ad_summary[:1]   #[:1]

    for i in r_data['keywordList'][:1] :
        pc = i['monthlyPcQcCnt']
        #pc = pc.replace("< 10", "10")
        mobile = i['monthlyMobileQcCnt']
        #mobile = mobile.replace("< 10", "10")
        
        try : 
            search_volumnes = str(int(pc) + int(mobile))
        except :
            search_volumnes = '10'
        #print(search_volumnes)
        print(str(j)+','+str(kw)+','+str(search_volumnes))
        f.write(str(j)+','+str(kw)+','+str(search_volumnes)+'\n')
    
    time.sleep(3) #3초

f.close()

print("네이버 데이터랩 Top 500 키워드 검색량 뽑기 완료")






#################### 네이버 데이터랩 Top 500 키워드 MS SQL에 집어넣기 ####################


#import pymssql
#import pandas as pd


# utf8, CP949 로 해야 한글 안 깨짐

conn = pymssql.connect(server='localhost', user='pyuser', password='Dnflskfk12!', database='mytest' ,  charset='utf8', autocommit=True)



naver_query = '''

IF OBJECT_ID(N'tempdb..#naver_top500') IS NOT NULL
DROP TABLE #naver_top500 

create table #naver_top500 (
No nvarchar(max) null,
keyword nvarchar(max) null,
SVs nvarchar(max) null
)

bulk insert #naver_top500  from 'C:/Users/user/raw/product_kw/naverdatalabtop500_volumes.csv'  with (firstrow=2, fieldterminator = ',' ,codepage='65001', rowterminator = '\n', keepnulls )


insert into mytest..naver_top500
select convert(char(10), getdate(), 120) as date,* from    #naver_top500

select * 
from mytest..naver_top500 
with (nolock) ; 

'''
# codepage='65001'


data = pd.read_sql(sql=naver_query, con=conn)

conn.commit()
conn.close()



print("네이버 데이터랩 Top 500 키워드 MS SQL에 집어넣기 완료")


# In[ ]:




